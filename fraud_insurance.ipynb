{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "850a4c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install kagglehub\n",
    "# %pip install pandas\n",
    "# %pip install pennylane\n",
    "# %pip install torch\n",
    "# %pip install scikit-learn\n",
    "# %pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "726c9e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader, WeightedRandomSampler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import (precision_recall_curve, average_precision_score, average_precision_score, f1_score, balanced_accuracy_score,\n",
    "                             roc_curve, auc, brier_score_loss,\n",
    "                             classification_report, confusion_matrix, accuracy_score)\n",
    "from sklearn.calibration import calibration_curve\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pennylane as qml\n",
    "from tqdm import tqdm\n",
    "import pennylane as qml\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "import kagglehub\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f26f2f1",
   "metadata": {},
   "source": [
    "DATA PREPROCESS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4c10bbcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kaggle dataset found: rohitrox/healthcare-provider-fraud-detection-analysis\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Provider</th>\n",
       "      <th>PotentialFraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PRV51001</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PRV51003</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PRV51004</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PRV51005</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PRV51007</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Provider PotentialFraud\n",
       "0  PRV51001             No\n",
       "1  PRV51003            Yes\n",
       "2  PRV51004             No\n",
       "3  PRV51005            Yes\n",
       "4  PRV51007             No"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Provider feature matrix (post-clean): (5410, 37)\n"
     ]
    }
   ],
   "source": [
    "# Robust cleaners\n",
    "def clean_dataframe(df: pd.DataFrame, *, drop_high_nan=True, high_nan_ratio=0.95) -> pd.DataFrame:\n",
    "    \"\"\"General cleaner: empty strings -> NaN, drop all-empty cols, optional high-NaN drop,\n",
    "    then median/mode impute. Also removes +/-inf.\"\"\"\n",
    "    d = df.copy()\n",
    "\n",
    "    for c in d.columns:\n",
    "        if d[c].dtype == \"O\":\n",
    "            d[c] = d[c].astype(str).str.strip()\n",
    "    d = d.replace(r'^\\s*$', np.nan, regex=True)\n",
    "    d = d.dropna(axis=1, how=\"all\")\n",
    "    d = d.replace([np.inf, -np.inf], np.nan)\n",
    "    if drop_high_nan and len(d):\n",
    "        nan_ratio = d.isna().mean()\n",
    "        keep_cols = nan_ratio[nan_ratio <= high_nan_ratio].index\n",
    "        d = d[keep_cols]\n",
    "\n",
    "    for c in d.select_dtypes(include=[np.number]).columns:\n",
    "        if d[c].isna().any():\n",
    "            med = d[c].median()\n",
    "            d[c] = d[c].fillna(med if pd.notna(med) else 0.0)\n",
    "\n",
    "    for c in d.select_dtypes(exclude=[np.number]).columns:\n",
    "        if d[c].isna().any():\n",
    "            mode_vals = d[c].mode(dropna=True)\n",
    "            fillv = mode_vals.iloc[0] if not mode_vals.empty else \"missing\"\n",
    "            d[c] = d[c].fillna(fillv)\n",
    "\n",
    "    return d\n",
    "\n",
    "\n",
    "def _to_num01(s: pd.Series) -> pd.Series:\n",
    "    s = s.astype(str).str.strip().str.lower()\n",
    "    if s.isin([\"yes\",\"no\"]).any():\n",
    "        return (s == \"yes\").astype(float)\n",
    "    if s.isin([\"true\",\"false\"]).any():\n",
    "        return (s == \"true\").astype(float)\n",
    "    with np.errstate(all=\"ignore\"):\n",
    "        v = pd.to_numeric(s, errors=\"coerce\")\n",
    "    return v\n",
    "\n",
    "\n",
    "def build_provider_agg(df, provider_col=\"Provider\"):\n",
    "    \"\"\"Aggregate claim-level rows to provider-level features with robust cleaning.\"\"\"\n",
    "    if provider_col not in df.columns:\n",
    "        return None\n",
    "    d = clean_dataframe(df)\n",
    "    for c in d.columns:\n",
    "        if d[c].dtype == \"O\":\n",
    "            lc = str(c).lower()\n",
    "            if any(k in lc for k in [\"chronic\", \"fraud\", \"yes\", \"no\", \"diabetes\", \"alzheimer\", \"heart\", \"cancer\"]):\n",
    "                d[c] = _to_num01(d[c])\n",
    "\n",
    "    for c in d.columns:\n",
    "        cl = c.lower()\n",
    "        if any(k in cl for k in [\"admit\", \"adm\", \"disch\", \"dsch\", \"date\"]):\n",
    "            try:\n",
    "                d[c] = pd.to_datetime(d[c], errors=\"coerce\")\n",
    "            except Exception:\n",
    "                pass\n",
    "\n",
    "    adm = next((c for c in d.columns if re.search(\"admit|adm\", c, re.I)), None)\n",
    "    dis = next((c for c in d.columns if re.search(\"disch|dsch|dis\", c, re.I)), None)\n",
    "    if adm and dis and np.issubdtype(d[adm].dtype, np.datetime64) and np.issubdtype(d[dis].dtype, np.datetime64):\n",
    "        d[\"_LOS_\"] = (d[dis] - d[adm]).dt.days.astype(\"float\")\n",
    "    else:\n",
    "        d[\"_LOS_\"] = np.nan\n",
    "\n",
    "    id_like = (\"claimid\",\"claimnumber\",\"patientid\",\"beneid\",\"memberid\",\"claim_id\",\"claim_number\",\"patient_id\",\"bene_id\")\n",
    "    num_cols_local = []\n",
    "    for c in d.columns:\n",
    "        if c == provider_col: \n",
    "            continue\n",
    "        cl = c.lower()\n",
    "        if any(tok in cl for tok in id_like):\n",
    "            continue\n",
    "        if pd.api.types.is_numeric_dtype(d[c]):\n",
    "            num_cols_local.append(c)\n",
    "\n",
    "    grp = d.groupby(provider_col, dropna=False)\n",
    "    feats = pd.DataFrame(index=grp.size().index)\n",
    "    feats.index.name = provider_col\n",
    "\n",
    "    feats[\"n_rows\"] = grp.size().astype(float)\n",
    "    if \"BeneID\" in d.columns:\n",
    "        feats[\"n_unique_bene\"] = grp[\"BeneID\"].nunique().astype(float)\n",
    "\n",
    "    feats[\"los_mean\"] = grp[\"_LOS_\"].mean()\n",
    "    feats[\"los_std\"]  = grp[\"_LOS_\"].std()\n",
    "\n",
    "    money_cols = [c for c in d.columns if pd.api.types.is_numeric_dtype(d[c]) and re.search(\"reimb|paid|pay|amount|amt|charge\", c, re.I)]\n",
    "    pick_cols = money_cols if money_cols else num_cols_local[:10]\n",
    "\n",
    "    for c in pick_cols:\n",
    "        g = grp[c]\n",
    "        feats[f\"{c}_sum\"]  = g.sum()\n",
    "        feats[f\"{c}_mean\"] = g.mean()\n",
    "        feats[f\"{c}_std\"]  = g.std()\n",
    "        feats[f\"{c}_min\"]  = g.min()\n",
    "        feats[f\"{c}_max\"]  = g.max()\n",
    "\n",
    "    for c in [\"DiagnosisGroupCode\",\"ClaimType\",\"AttendingPhysician\",\"OperatingPhysician\",\"Gender\",\"Race\"]:\n",
    "        if c in d.columns:\n",
    "            feats[f\"{c}_nunique\"] = grp[c].nunique()\n",
    "\n",
    "    feats = feats.replace([np.inf, -np.inf], np.nan)\n",
    "    feats = clean_dataframe(feats, drop_high_nan=False)  # small cleanup post-agg\n",
    "    return feats\n",
    "\n",
    "\n",
    "\n",
    "FRAUD_KAGGLE_SLUGS = [\n",
    "    \"rohitrox/healthcare-provider-fraud-detection-analysis\",\n",
    "    \"shivamb/healthcare-provider-fraud-detection\",\n",
    "    \"luisfredgs/healthcare-provider-fraud-detection-analysis\",\n",
    "    \"govindkrishnareddy/healthcare-provider-fraud-detection-analysis\",\n",
    "]\n",
    "\n",
    "\n",
    "fraud_dir = None\n",
    "for slug in FRAUD_KAGGLE_SLUGS:\n",
    "    try:\n",
    "        fraud_dir = kagglehub.dataset_download(slug)\n",
    "        print(\"Kaggle dataset found:\", slug)\n",
    "        break\n",
    "    except Exception as e:\n",
    "        print(\"Tried:\", slug, \"->\", e)\n",
    "assert fraud_dir is not None, \"Could not download provider fraud dataset from Kaggle with known slugs.\"\n",
    "\n",
    "\n",
    "\n",
    "data_path = Path(fraud_dir)\n",
    "csv_files = list(data_path.rglob(\"*.csv\"))\n",
    "assert csv_files, f\"No CSVs found under {data_path}\"\n",
    "\n",
    "TARGET_CANDIDATES = [\"PotentialFraud\", \"Fraud\", \"fraud\", \"IsFraud\", \"FraudFound_P\", \"target\"]\n",
    "df_fraud = None\n",
    "target_col = None\n",
    "SRC_CSV = None\n",
    "\n",
    "for csvp in csv_files:\n",
    "    try:\n",
    "        raw = pd.read_csv(csvp)\n",
    "        dft = clean_dataframe(raw)\n",
    "        for tcol in TARGET_CANDIDATES:\n",
    "            if tcol in dft.columns:\n",
    "                df_fraud  = dft\n",
    "                target_col= tcol\n",
    "                SRC_CSV   = csvp\n",
    "                break\n",
    "        if df_fraud is not None:\n",
    "            break\n",
    "    except Exception:\n",
    "        continue\n",
    "\n",
    "assert df_fraud is not None, f\"None of the CSVs had a known fraud target column {TARGET_CANDIDATES}\"\n",
    "\n",
    "display(df_fraud.head())\n",
    "\n",
    "\n",
    "def normalize_target(col):\n",
    "    if col.dtype == \"O\":\n",
    "        s = col.astype(str).str.strip().str.lower()\n",
    "        if s.isin([\"yes\",\"no\"]).any():     return (s == \"yes\").astype(int)\n",
    "        if s.isin([\"true\",\"false\"]).any(): return (s == \"true\").astype(int)\n",
    "        if s.isin([\"fraud\",\"nonfraud\",\"not_fraud\",\"legit\"]).any():\n",
    "            return s.isin([\"fraud\"]).astype(int)\n",
    "        try:\n",
    "            return pd.to_numeric(s, errors=\"coerce\").fillna(0).astype(int)\n",
    "        except Exception:\n",
    "            return (s == s.unique()[-1]).astype(int)\n",
    "    v = pd.to_numeric(col, errors=\"coerce\").fillna(0)\n",
    "    if set(np.unique(v)) - {0,1}:\n",
    "        mv = v.mode().iloc[0]\n",
    "        v = (v != mv).astype(int)\n",
    "    return v\n",
    "\n",
    "\n",
    "y_bin = normalize_target(df_fraud[target_col]).astype(int)\n",
    "y_labels = y_bin.map({0: \"nonfraud\", 1: \"fraud\"}).astype(\"category\")\n",
    "\n",
    "X_fraud = df_fraud.drop(columns=[target_col]).copy()\n",
    "\n",
    "\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "    X_fraud, y_labels, test_size=0.30, stratify=y_labels, random_state=42\n",
    ")\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.50, stratify=y_temp, random_state=42\n",
    ")\n",
    "\n",
    "num_cols = [c for c in X_fraud.columns if pd.api.types.is_numeric_dtype(X_fraud[c])]\n",
    "cat_cols = [c for c in X_fraud.columns if c not in num_cols]\n",
    "\n",
    "\n",
    "csv_paths = list(data_path.rglob(\"*.csv\"))\n",
    "provider_features = None\n",
    "\n",
    "for p in csv_paths:\n",
    "    try:\n",
    "        dfp_raw = pd.read_csv(p)\n",
    "        if \"Provider\" not in dfp_raw.columns:\n",
    "            continue\n",
    "        dfp = clean_dataframe(dfp_raw)\n",
    "        agg = build_provider_agg(dfp, provider_col=\"Provider\")\n",
    "        if agg is None or agg.empty:\n",
    "            continue\n",
    "        agg.columns = [f\"{p.stem}__{c}\" for c in agg.columns]\n",
    "        agg = agg.reset_index()\n",
    "        provider_features = agg if provider_features is None else provider_features.merge(agg, on=\"Provider\", how=\"outer\")\n",
    "    except Exception:\n",
    "        continue\n",
    "\n",
    "assert provider_features is not None and not provider_features.empty, \"No provider-level features could be built.\"\n",
    "\n",
    "\n",
    "labels_df = df_fraud[[target_col]].copy()\n",
    "labels_df = labels_df.rename(columns={target_col: \"FraudLabel\"})\n",
    "labels_df[\"FraudLabel\"] = (normalize_target(labels_df[\"FraudLabel\"]) > 0).astype(int)\n",
    "labels_df[\"Provider\"] = df_fraud[\"Provider\"] if \"Provider\" in df_fraud.columns else df_fraud.iloc[:, 0]\n",
    "\n",
    "data_all = labels_df.merge(provider_features, on=\"Provider\", how=\"left\")\n",
    "data_all = data_all.drop(columns=[\"Provider\"])\n",
    "\n",
    "data_all = clean_dataframe(data_all, drop_high_nan=True, high_nan_ratio=0.98)\n",
    "\n",
    "y_bin = data_all[\"FraudLabel\"].astype(int).values\n",
    "X_all = data_all.drop(columns=[\"FraudLabel\"]).copy()\n",
    "\n",
    "print(\"Provider feature matrix (post-clean):\", X_all.shape)\n",
    "\n",
    "\n",
    "Xtr, Xte, ytr, yte = train_test_split(X_all, y_bin, test_size=0.20, stratify=y_bin, random_state=42)\n",
    "Xtr, Xva, ytr, yva = train_test_split(Xtr, ytr, test_size=0.25, stratify=ytr, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "Xtr = scaler.fit_transform(Xtr)\n",
    "Xva = scaler.transform(Xva)\n",
    "Xte = scaler.transform(Xte)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "Xt = torch.tensor(Xtr, dtype=torch.float32)\n",
    "Xv = torch.tensor(Xva, dtype=torch.float32)\n",
    "Xs = torch.tensor(Xte, dtype=torch.float32)\n",
    "yt_t = torch.tensor(ytr, dtype=torch.long)\n",
    "yv_t = torch.tensor(yva, dtype=torch.long)\n",
    "ys_t = torch.tensor(yte, dtype=torch.long)\n",
    "\n",
    "\n",
    "counts = np.bincount(ytr, minlength=2).astype(float); counts[counts==0] = 1\n",
    "class_weights = torch.tensor((counts.sum()/(2*counts)).astype(np.float32))\n",
    "sample_weights = class_weights[yt_t].double()\n",
    "\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    TensorDataset(Xt, yt_t), batch_size=64,\n",
    "    sampler=WeightedRandomSampler(sample_weights, len(sample_weights), replacement=True)\n",
    ")\n",
    "\n",
    "\n",
    "val_loader   = DataLoader(TensorDataset(Xv, yv_t), batch_size=64, shuffle=False)\n",
    "test_loader  = DataLoader(TensorDataset(Xs, ys_t), batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc3662fa",
   "metadata": {},
   "source": [
    "Quantum-Hybrid QNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0411b4c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "qdev = qml.device(\"default.qubit\", wires=6)\n",
    "\n",
    "@qml.qnode(qdev, interface=\"torch\")\n",
    "def q_circuit(inputs, weights):\n",
    "    # angle embedding into 6 wires\n",
    "    for i in range(6):\n",
    "        qml.RY(inputs[i % inputs.shape[0]], wires=i)\n",
    "    qml.templates.BasicEntanglerLayers(weights, wires=range(6))\n",
    "    return [qml.expval(qml.PauliZ(i)) for i in range(2)]\n",
    "\n",
    "q_layer1 = qml.qnn.TorchLayer(q_circuit, {\"weights\": (4,6)}).to(device)\n",
    "q_layer2 = qml.qnn.TorchLayer(q_circuit, {\"weights\": (4,6)}).to(device)\n",
    "\n",
    "\n",
    "class HybridQuantumFraudQNNModel(nn.Module):\n",
    "    def __init__(self, in_dim, hid=64, p=0.2):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(in_dim, hid)\n",
    "        self.bn1 = nn.BatchNorm1d(hid)\n",
    "        self.drop = nn.Dropout(p)\n",
    "        self.fc2 = nn.Linear(hid, 6)\n",
    "\n",
    "        self.qnn1 = q_layer1\n",
    "        self.qnn2 = q_layer2\n",
    "\n",
    "        self.out = nn.Linear(2, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.drop(torch.relu(self.bn1(self.fc1(x))))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = torch.stack([self.qnn1(xi) for xi in x], dim=0)\n",
    "        x = torch.stack([self.qnn2(xi) for xi in x], dim=0)\n",
    "\n",
    "        return self.out(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbc9180c",
   "metadata": {},
   "source": [
    "Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "63098808",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 | Val AP(fraud)=0.507 | Best macro-F1=0.514 @ Thr=0.324 | Balanced Acc=0.519\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 | Val AP(fraud)=0.509 | Best macro-F1=0.557 @ Thr=0.337 | Balanced Acc=0.544\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 | Val AP(fraud)=0.822 | Best macro-F1=0.926 @ Thr=0.349 | Balanced Acc=0.941\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 | Val AP(fraud)=0.983 | Best macro-F1=0.981 @ Thr=0.364 | Balanced Acc=0.979\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 | Val AP(fraud)=0.999 | Best macro-F1=0.992 @ Thr=0.378 | Balanced Acc=0.990\n",
      "Best Val AP(fraud)=0.999 with threshold=0.378\n"
     ]
    }
   ],
   "source": [
    "def train_fraud_model(model, train_loader, val_loader,\n",
    "                      epochs=10, patience=4, lr=3e-4, wd=1e-5,\n",
    "                      class_weights=None):\n",
    "    model.to(device)\n",
    "    optim = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=wd)\n",
    "    crit  = nn.CrossEntropyLoss(\n",
    "        weight=class_weights.to(device) if class_weights is not None else None,\n",
    "        label_smoothing=0.03\n",
    "    )\n",
    "\n",
    "    best_ap, best_state, best_thr = -np.inf, None, 0.5\n",
    "    patience_ctr = 0\n",
    "\n",
    "    for ep in range(1, epochs+1):\n",
    "        # -------- Train --------\n",
    "        model.train()\n",
    "        loop = tqdm(train_loader, desc=f\"Epoch [{ep}/{epochs}]\", leave=False)\n",
    "        for xb, yb in loop:\n",
    "            xb, yb = xb.to(device), yb.to(device)\n",
    "            optim.zero_grad()\n",
    "            logits = model(xb)\n",
    "            loss = crit(logits, yb)\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            optim.step()\n",
    "            loop.set_postfix(loss=float(loss))\n",
    "\n",
    "        # -------- Validate --------\n",
    "        model.eval()\n",
    "        probs, true = [], []\n",
    "        with torch.no_grad():\n",
    "            for xv, yv in val_loader:\n",
    "                xv = xv.to(device)\n",
    "                p = torch.softmax(model(xv), dim=1)[:, 1]  # P(fraud)\n",
    "                probs.append(p.cpu().numpy()); true.append(yv.numpy())\n",
    "        probs = np.concatenate(probs)\n",
    "        true  = np.concatenate(true).astype(int)\n",
    "\n",
    "        # monitor AP(fraud)\n",
    "        ap = average_precision_score(true, probs)\n",
    "\n",
    "        # threshold tuning for macro-F1 (finer grid)\n",
    "        thr_grid = np.linspace(0.01, 0.99, 1000)\n",
    "        f1s   = [f1_score(true, (probs >= t).astype(int), average=\"macro\") for t in thr_grid]\n",
    "        baccs = [balanced_accuracy_score(true, (probs >= t).astype(int)) for t in thr_grid]\n",
    "\n",
    "        i_f1       = int(np.nanargmax(f1s))\n",
    "        t_best     = float(thr_grid[i_f1])\n",
    "        f1_best    = float(f1s[i_f1])\n",
    "        bacc_best  = float(baccs[i_f1])\n",
    "\n",
    "        print(\n",
    "            f\"Epoch {ep} | Val AP(fraud)={ap:.3f} | \"\n",
    "            f\"Best macro-F1={f1_best:.3f} @ Thr={t_best:.3f} | \"\n",
    "            f\"Balanced Acc={bacc_best:.3f}\"\n",
    "        )\n",
    "\n",
    "        # early stopping on AP(fraud)\n",
    "        if ap > best_ap + 1e-4:\n",
    "            best_ap    = ap\n",
    "            best_state = {k: v.detach().cpu().clone() for k, v in model.state_dict().items()}\n",
    "            best_thr   = t_best\n",
    "            patience_ctr = 0\n",
    "        else:\n",
    "            patience_ctr += 1\n",
    "            if patience_ctr >= patience:\n",
    "                print(\"Early stopping.\")\n",
    "                break\n",
    "\n",
    "    if best_state:\n",
    "        model.load_state_dict(best_state)\n",
    "    print(f\"Best Val AP(fraud)={best_ap:.3f} with threshold={best_thr:.3f}\")\n",
    "    return best_thr\n",
    "\n",
    "model = HybridQuantumFraudQNNModel(in_dim=Xtr.shape[1], hid=64, p=0.2)\n",
    "\n",
    "best_thr = train_fraud_model(\n",
    "    model, train_loader, val_loader,\n",
    "    epochs=5, patience=4, class_weights=class_weights\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a26f5169",
   "metadata": {},
   "source": [
    "Evaluate on test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fbca5e3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC=1.000 | PR-AP=0.998 | Brier=0.164\n",
      "Threshold: 0.37786786786786786\n",
      "Accuracy: 99.72%\n",
      "\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    nonfraud       1.00      1.00      1.00       981\n",
      "       fraud       0.98      0.99      0.99       101\n",
      "\n",
      "    accuracy                           1.00      1082\n",
      "   macro avg       0.99      0.99      0.99      1082\n",
      "weighted avg       1.00      1.00      1.00      1082\n",
      "\n",
      "Confusion matrix:\n",
      " [[979   2]\n",
      " [  1 100]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'roc_auc': 0.9998082377045043,\n",
       "  'pr_ap': 0.9980634810025565,\n",
       "  'brier': 0.16402428698441854},\n",
       " array([0.3757431 , 0.37572235, 0.3757747 , ..., 0.37571874, 0.37571317,\n",
       "        0.37579125], dtype=float32),\n",
       " array([0, 0, 0, ..., 0, 0, 0]),\n",
       " array([0, 0, 0, ..., 0, 0, 0]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def eval_with_threshold(model, loader, thr=0.5, title=\"Model (Test)\"):\n",
    "    thr = float(np.atleast_1d(thr)[0])\n",
    "\n",
    "    model.eval()\n",
    "    probs, true = [], []\n",
    "    with torch.no_grad():\n",
    "        for xb, yb in loader:\n",
    "            xb = xb.to(device)\n",
    "            logits = model(xb)\n",
    "            p = torch.softmax(logits, dim=1)[:, 1]\n",
    "            probs.append(p.cpu().numpy()); true.append(yb.numpy())\n",
    "    probs = np.concatenate(probs).ravel()\n",
    "    true  = np.concatenate(true).astype(int).ravel()\n",
    "\n",
    "    fpr, tpr, _ = roc_curve(true, probs, pos_label=1)\n",
    "    rocA = auc(fpr, tpr)\n",
    "    pr, rc, _ = precision_recall_curve(true, probs, pos_label=1)\n",
    "    ap = average_precision_score(true, probs)\n",
    "    pt, pp = calibration_curve(true, probs, n_bins=10, strategy=\"uniform\")\n",
    "    brier = brier_score_loss(true, probs)\n",
    "\n",
    "    print(f\"ROC-AUC={rocA:.3f} | PR-AP={ap:.3f} | Brier={brier:.3f}\")\n",
    "\n",
    "    pred = (probs >= thr).astype(int)\n",
    "    print(\"Threshold:\", thr)\n",
    "    print(\"Accuracy:\", f\"{accuracy_score(true, pred)*100:.2f}%\")\n",
    "    print(\"\\nClassification report:\\n\",\n",
    "          classification_report(true, pred, target_names=[\"nonfraud\",\"fraud\"]))\n",
    "    print(\"Confusion matrix:\\n\", confusion_matrix(true, pred))\n",
    "\n",
    "    return {\"roc_auc\": float(rocA), \"pr_ap\": float(ap), \"brier\": float(brier)}, probs, true, pred\n",
    "\n",
    "eval_with_threshold(model, test_loader, thr=best_thr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7756d677",
   "metadata": {},
   "source": [
    "Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ee88ebb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved hybrid QNN to ./insurance_artifacts/models/insurance_fraud_hybrid_quantum.pt\n"
     ]
    }
   ],
   "source": [
    "os.makedirs(\"./insurance_artifacts/models\", exist_ok=True)\n",
    "torch.save(model.state_dict(), \"./insurance_artifacts/models/insurance_fraud_hybrid_quantum.pt\")\n",
    "print(\"Saved hybrid QNN to ./insurance_artifacts/models/insurance_fraud_hybrid_quantum.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b8b88c9",
   "metadata": {},
   "source": [
    "Upload model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d93e7a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# uploaded_fraud = torch.load(\"./models/insurance_fraud_hybrid_quantum.pt\", map_location=\"cpu\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "train",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
